{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad838c10",
   "metadata": {},
   "source": [
    "# Merge_all — Build a Unified Dataset for **Maneuvers** (single-boat)\n",
    "\n",
    "This notebook aggregates **validated maneuver intervals** (from `summary.json`) across all runs into a single, analysis-ready CSV.  \n",
    "It **does not compare two boats**: each maneuver slice comes from one boat’s log and is annotated with run/rider metadata.\n",
    "\n",
    "---\n",
    "\n",
    "## Inputs\n",
    "\n",
    "- **`summary.json`** — produced by `mainCOG`; for each run it lists validated maneuvers with:\n",
    "  - `maneuver_index`, `maneuver_type`, `start_time`, `end_time`, `duration`, …\n",
    "- **Data root** (e.g., `../Data_Sailnjord/Maneuvers`) with folders: /date/person/run/single_file.csv\n",
    "Each run folder must contain **exactly one CSV**.\n",
    "\n",
    "- **Helper**: `report_fct.filter_interval(df, start, end)` to clip time windows.\n",
    "\n",
    "---\n",
    "\n",
    "## What the code does\n",
    "\n",
    "1. **Load `summary.json`** and iterate all runs & their maneuver intervals.  \n",
    "2. **Open the run’s CSV** and **slice** rows to `[start_time, end_time]`.  \n",
    "3. **Annotate** each sliced row with:\n",
    " - `run`, `rider_name`, `boat_name`, `maneuver_index`, `maneuver_type`,  \n",
    "   `interval_duration`, `start_time`, `end_time`.\n",
    "4. **Recompute rigging-line features** (when `Line_L/Line_R/Line_C` exist):\n",
    " - Sort per-row magnitudes → `Line_R2`(min), `Line_L2`(mid), `Line_C2`(max)  \n",
    " - `side_line2 = Line_L2 + Line_R2`  \n",
    " - `total_line2 = side_line2 + Line_C2`\n",
    "5. **Concatenate all slices**, sort by `SecondsSince1970`, and **export**.\n",
    "\n",
    "---\n",
    "\n",
    "## Output\n",
    "\n",
    "- **`all_data.csv`** — long, tidy table of maneuver rows across all runs containing telemetry\n",
    "(`SecondsSince1970`, `Lat`, `Lon`, `SOG`, `VMG`, `COG`, `TWA`, `TWD`, `TWS`, `Heel_Lwd`, …),\n",
    "maneuver metadata, and optional derived line metrics (`Line_*2`, `side_line2`, `total_line2`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e0ac419",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T13:15:39.612185Z",
     "iopub.status.busy": "2025-09-13T13:15:39.611186Z",
     "iopub.status.idle": "2025-09-13T13:15:41.666585Z",
     "shell.execute_reply": "2025-09-13T13:15:41.665705Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from report_fct import filter_interval\n",
    "import pandas as pd\n",
    "\n",
    "def build_csv_from_summary(summary_path, data_root, output_csv=\"all_data.csv\"):\n",
    "    # Load the summary JSON\n",
    "    with open(summary_path, \"r\") as f:\n",
    "        summary = json.load(f)\n",
    "\n",
    "    all_rows = []\n",
    "\n",
    "    # Iterate over each run entry in the summary\n",
    "    for run_entry in summary:\n",
    "        run_name = run_entry[\"run\"]\n",
    "        date = run_entry[\"date\"]  # e.g., \"08_06\"\n",
    "        person = run_entry[\"person\"]  # e.g., \"Gian\"\n",
    "        intervals = run_entry[\"intervals\"]\n",
    "\n",
    "        # Ensure intervals is a list\n",
    "        if not isinstance(intervals, list):\n",
    "            print(f\"⚠️ Invalid interval data for {run_name}: expected a list, found {type(intervals)}\")\n",
    "            continue\n",
    "\n",
    "        # Build the run folder path using date, person, and run name\n",
    "        run_path = os.path.join(data_root, date, person, run_name)\n",
    "        # Check if the run folder exists\n",
    "        if not os.path.isdir(run_path):\n",
    "            print(f\"⚠️ Run folder not found for {run_name} at {run_path}\")\n",
    "            continue\n",
    "\n",
    "        # Search for the CSV file in the run folder\n",
    "        csv_files = [f for f in os.listdir(run_path) if f.endswith(\".csv\")]\n",
    "        if len(csv_files) != 1:\n",
    "            print(f\"⚠️ Skipping {run_name}: expected 1 CSV, found {len(csv_files)}\")\n",
    "            continue\n",
    "\n",
    "        # Build the full path to the CSV file\n",
    "        csv_path = os.path.join(run_path, csv_files[0])\n",
    "\n",
    "        # Read the CSV file into a DataFrame\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error reading CSV file {csv_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Process each interval in the run\n",
    "        try:\n",
    "            print(f\"✔ Processing run: {run_name}, total intervals: {len(intervals)}\")\n",
    "\n",
    "            for i, interval in enumerate(intervals):\n",
    "                start, end = interval[\"start_time\"], interval[\"end_time\"]\n",
    "                df_filtered = filter_interval(df, start, end)  # Pass the DataFrame, not the path\n",
    "                # Add necessary metadata to each row\n",
    "                df_filtered[\"run\"] = run_name\n",
    "                df_filtered[\"rider_name\"] = person\n",
    "                df_filtered[\"boat_name\"] = csv_files[0].replace(\".csv\", \"\")\n",
    "                df_filtered[\"maneuver_index\"] = interval[\"maneuver_index\"]\n",
    "                df_filtered[\"maneuver_type\"] = interval[\"maneuver_type\"]\n",
    "                df_filtered[\"interval_duration\"] = interval[\"duration\"]\n",
    "                df_filtered[\"start_time\"] = interval[\"start_time\"]\n",
    "                df_filtered[\"end_time\"] = interval[\"end_time\"]\n",
    "                \n",
    "                # Réaffectation arbitraire des lignes en triant les valeurs\n",
    "                lines = df_filtered[[\"Line_C\", \"Line_L\", \"Line_R\"]].values\n",
    "                sorted_lines = np.sort(lines, axis=1)  # Sorting row-wise\n",
    "\n",
    "                # Creating new columns with sorted line values\n",
    "                df_filtered[\"Line_R2\"] = sorted_lines[:, 0]  # Smallest\n",
    "                df_filtered[\"Line_L2\"] = sorted_lines[:, 1]  # Middle\n",
    "                df_filtered[\"Line_C2\"] = sorted_lines[:, 2]  # Largest\n",
    "                df_filtered[\"side_line2\"] = df_filtered[\"Line_L2\"] + df_filtered[\"Line_R2\"]\n",
    "                df_filtered[\"total_line2\"] = df_filtered[\"side_line2\"] + df_filtered[\"Line_C2\"]\n",
    "                \n",
    "                all_rows.append(df_filtered)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing run {run_name}, interval {i + 1}: {type(e).__name__} - {e}\")\n",
    "            continue\n",
    "\n",
    "    # Final save\n",
    "    if not all_rows:\n",
    "        print(\"❌ No valid data found.\")\n",
    "        return\n",
    "\n",
    "    # Combine all rows into a single DataFrame and save to CSV\n",
    "    df_global = pd.concat(all_rows, ignore_index=True)\n",
    "    df_global = df_global.sort_values(by='SecondsSince1970', ascending=True)\n",
    "    df_global.to_csv(output_csv, index=False)\n",
    "    print(f\"✅ Global CSV saved to: {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dbb311c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-13T13:15:41.666585Z",
     "iopub.status.busy": "2025-09-13T13:15:41.666585Z",
     "iopub.status.idle": "2025-09-13T13:15:43.805152Z",
     "shell.execute_reply": "2025-09-13T13:15:43.805152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Processing run: 08_06_Run1, total intervals: 12\n",
      "✔ Processing run: 08_06_Run2, total intervals: 11\n",
      "✔ Processing run: 08_06_Run3, total intervals: 11\n",
      "✔ Processing run: 08_06_Run4, total intervals: 10\n",
      "✔ Processing run: 08_06_Run5, total intervals: 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Processing run: 08_06_Run1, total intervals: 13\n",
      "✔ Processing run: 08_06_Run2, total intervals: 11\n",
      "✔ Processing run: 08_06_Run3, total intervals: 12\n",
      "✔ Processing run: 08_06_Run4, total intervals: 11\n",
      "✔ Processing run: 08_06_Run5, total intervals: 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Processing run: 08_06_Run6, total intervals: 11\n",
      "✔ Processing run: 11_06_Run1, total intervals: 12\n",
      "✔ Processing run: 11_06_Run2, total intervals: 11\n",
      "✔ Processing run: 11_06_Run3, total intervals: 12\n",
      "✔ Processing run: 11_06_Run4, total intervals: 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Processing run: 11_06_Run5, total intervals: 11\n",
      "✔ Processing run: 11_06_Run1, total intervals: 11\n",
      "✔ Processing run: 11_06_Run2, total intervals: 12\n",
      "✔ Processing run: 11_06_Run3, total intervals: 12\n",
      "✔ Processing run: 11_06_Run4, total intervals: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Processing run: 11_06_Run5, total intervals: 12\n",
      "✔ Processing run: 11_06_Run6, total intervals: 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Global CSV saved to: all_data.csv\n"
     ]
    }
   ],
   "source": [
    "build_csv_from_summary(\n",
    "    summary_path=\"summary.json\",\n",
    "    data_root=\"../Data_Sailnjord/Maneuvers\",\n",
    "    output_csv=\"all_data.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cfb404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sail2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
