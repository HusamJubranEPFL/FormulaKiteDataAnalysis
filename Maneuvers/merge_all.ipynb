{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e0ac419",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T15:09:16.774790Z",
     "iopub.status.busy": "2025-07-29T15:09:16.774790Z",
     "iopub.status.idle": "2025-07-29T15:09:19.106827Z",
     "shell.execute_reply": "2025-07-29T15:09:19.106827Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from report_fct import filter_interval\n",
    "import pandas as pd\n",
    "\n",
    "def build_csv_from_summary(summary_path, data_root, output_csv=\"all_data.csv\"):\n",
    "    # Load the summary JSON\n",
    "    with open(summary_path, \"r\") as f:\n",
    "        summary = json.load(f)\n",
    "\n",
    "    all_rows = []\n",
    "\n",
    "    # Iterate over each run entry in the summary\n",
    "    for run_entry in summary:\n",
    "        run_name = run_entry[\"run\"]\n",
    "        date = run_entry[\"date\"]  # e.g., \"08_06\"\n",
    "        person = run_entry[\"person\"]  # e.g., \"Gian\"\n",
    "        intervals = run_entry[\"intervals\"]\n",
    "\n",
    "        # Ensure intervals is a list\n",
    "        if not isinstance(intervals, list):\n",
    "            print(f\"⚠️ Invalid interval data for {run_name}: expected a list, found {type(intervals)}\")\n",
    "            continue\n",
    "\n",
    "        # Build the run folder path using date, person, and run name\n",
    "        run_path = os.path.join(data_root, date, person, run_name)\n",
    "        # Check if the run folder exists\n",
    "        if not os.path.isdir(run_path):\n",
    "            print(f\"⚠️ Run folder not found for {run_name} at {run_path}\")\n",
    "            continue\n",
    "\n",
    "        # Search for the CSV file in the run folder\n",
    "        csv_files = [f for f in os.listdir(run_path) if f.endswith(\".csv\")]\n",
    "        if len(csv_files) != 1:\n",
    "            print(f\"⚠️ Skipping {run_name}: expected 1 CSV, found {len(csv_files)}\")\n",
    "            continue\n",
    "\n",
    "        # Build the full path to the CSV file\n",
    "        csv_path = os.path.join(run_path, csv_files[0])\n",
    "\n",
    "        # Read the CSV file into a DataFrame\n",
    "        try:\n",
    "            df = pd.read_csv(csv_path)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Error reading CSV file {csv_path}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Process each interval in the run\n",
    "        try:\n",
    "            print(f\"✔ Processing run: {run_name}, total intervals: {len(intervals)}\")\n",
    "\n",
    "            for i, interval in enumerate(intervals):\n",
    "                start, end = interval[\"start_time\"], interval[\"end_time\"]\n",
    "                df_filtered = filter_interval(df, start, end)  # Pass the DataFrame, not the path\n",
    "                # Add necessary metadata to each row\n",
    "                df_filtered[\"run\"] = run_name\n",
    "                df_filtered[\"rider_name\"] = person\n",
    "                df_filtered[\"boat_name\"] = csv_files[0].replace(\".csv\", \"\")\n",
    "                df_filtered[\"maneuver_index\"] = interval[\"maneuver_index\"]\n",
    "                df_filtered[\"maneuver_type\"] = interval[\"maneuver_type\"]\n",
    "                df_filtered[\"interval_duration\"] = interval[\"duration\"]\n",
    "                df_filtered[\"start_time\"] = interval[\"start_time\"]\n",
    "                df_filtered[\"end_time\"] = interval[\"end_time\"]\n",
    "                \n",
    "                # Réaffectation arbitraire des lignes en triant les valeurs\n",
    "                lines = df_filtered[[\"Line_C\", \"Line_L\", \"Line_R\"]].values\n",
    "                sorted_lines = np.sort(lines, axis=1)  # Sorting row-wise\n",
    "\n",
    "                # Creating new columns with sorted line values\n",
    "                df_filtered[\"Line_R2\"] = sorted_lines[:, 0]  # Smallest\n",
    "                df_filtered[\"Line_L2\"] = sorted_lines[:, 1]  # Middle\n",
    "                df_filtered[\"Line_C2\"] = sorted_lines[:, 2]  # Largest\n",
    "                df_filtered[\"side_line2\"] = df_filtered[\"Line_L2\"] + df_filtered[\"Line_R2\"]\n",
    "                df_filtered[\"total_line2\"] = df_filtered[\"side_line2\"] + df_filtered[\"Line_C2\"]\n",
    "                \n",
    "                all_rows.append(df_filtered)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing run {run_name}, interval {i + 1}: {type(e).__name__} - {e}\")\n",
    "            continue\n",
    "\n",
    "    # Final save\n",
    "    if not all_rows:\n",
    "        print(\"❌ No valid data found.\")\n",
    "        return\n",
    "\n",
    "    # Combine all rows into a single DataFrame and save to CSV\n",
    "    df_global = pd.concat(all_rows, ignore_index=True)\n",
    "    df_global = df_global.sort_values(by='SecondsSince1970', ascending=True)\n",
    "    df_global.to_csv(output_csv, index=False)\n",
    "    print(f\"✅ Global CSV saved to: {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dbb311c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-29T15:09:19.106827Z",
     "iopub.status.busy": "2025-07-29T15:09:19.106827Z",
     "iopub.status.idle": "2025-07-29T15:09:21.436945Z",
     "shell.execute_reply": "2025-07-29T15:09:21.435922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Processing run: 08_06_Run1, total intervals: 14\n",
      "✔ Processing run: 08_06_Run2, total intervals: 14\n",
      "✔ Processing run: 08_06_Run3, total intervals: 14\n",
      "✔ Processing run: 08_06_Run4, total intervals: 12\n",
      "✔ Processing run: 08_06_Run5, total intervals: 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Processing run: 08_06_Run1, total intervals: 14\n",
      "✔ Processing run: 08_06_Run2, total intervals: 12\n",
      "✔ Processing run: 08_06_Run3, total intervals: 13\n",
      "✔ Processing run: 08_06_Run4, total intervals: 12\n",
      "✔ Processing run: 08_06_Run5, total intervals: 12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Processing run: 08_06_Run6, total intervals: 11\n",
      "✔ Processing run: 11_06_Run1, total intervals: 14\n",
      "✔ Processing run: 11_06_Run2, total intervals: 13\n",
      "✔ Processing run: 11_06_Run3, total intervals: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Processing run: 11_06_Run4, total intervals: 14\n",
      "✔ Processing run: 11_06_Run5, total intervals: 13\n",
      "✔ Processing run: 11_06_Run1, total intervals: 12\n",
      "✔ Processing run: 11_06_Run2, total intervals: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Processing run: 11_06_Run3, total intervals: 13\n",
      "✔ Processing run: 11_06_Run4, total intervals: 13\n",
      "✔ Processing run: 11_06_Run5, total intervals: 14\n",
      "✔ Processing run: 11_06_Run6, total intervals: 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Global CSV saved to: all_data.csv\n"
     ]
    }
   ],
   "source": [
    "build_csv_from_summary(\n",
    "    summary_path=\"summary.json\",\n",
    "    data_root=\"../Data_Sailnjord/Maneuvers\",\n",
    "    output_csv=\"all_data.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cfb404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada_exam_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
